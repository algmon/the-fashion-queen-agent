# an intelligent AI agent for fashion from Suanfamama
## News
* 2025-02-13 We upload our meeting note about how to implement the cognitive cycle
* 2025-02-11 We update our demo for agent perception and planning
* 2025-02-10 We add one demo for agent perception
* 2025-02-05 the up-to-date repo is here: https://gitee.com/suanfamama/the-fashion-queen-agent
* 2025-02-04 We have our pre-print version of wisdom.graph.py implementation ready
* 2025-02-03 We have our pre-print version of paper ready titled Improved Methods for AI Agent Pruning

## AI agent goal
* the core task is to CAPTURE the beauty and SHARE them with the beloved ones for fashion

## AI agent outcome showcase
![](./showcase/1.png)
![](./showcase/2.png)

## AI agent technical aspect
### unified framework for both hardware and software
* ROS and Genesis for simulation

### unified framework for internal and external
* Tools such as sequential models, neural network etc to simulate the perception, planning, reasoning and action space in env for fashion

### unified framework for agents with env
* Agents to communicate for collaboration and competition
* learning from the env

### unified framework for basic living and advanced beauty appreciation
* Beyond basic living, there is beauty.

### code
* The improved MIT license is applied and please SEND an email to mama.xiao@suanfamama.com for general inquiries

## project & product code
* transformer^3

## core team & contributors
* anying, Suanfamama, anying@suanfamama.com
* youling, Suanfamama, youling@suanfamama.com
* jinpei, Suanfamama, jinpei@suanfamama.com
* wei, Suanfamama, wei.huang@suanfamama.com
* wei, Suanfamama, wei@suanfamama.com
* mama, Suanfamama, mama.xiao@suanfamama.com

## referneces part 1 - Computer Scientists
### Tier 1
* Weimin Shen, https://viterbi-web.usc.edu/~wmshen/, for the contribution of adaptive, self-reconfigurable, autonomous robots and systems
* Kaiming He, https://people.csail.mit.edu/kaiming/, for the contribution of large vision models
* Kevin Knight, https://kevincrawfordknight.github.io/, for the contribution of language understanding
* Yuanlie He, for the contribution of scene understanding & reconstruction
* Yongquan Yu, for the contribution of weights adaptation
* Leonard Adleman, https://adleman.usc.edu/, for the contribution of encription and decryption
* Yuhui Quan, https://csyhquan.github.io/, for the contribution of models for visual signal processing & understanding
* Torsten Suel, http://engineering.nyu.edu/~suel/, for the contribution of pruning tech
* Juan Rodriguez, https://engineering.nyu.edu/life-tandon/student-life/commencement/2021/profiles/juan-rodriguez, for the contribution of the agent's inverted index pruning
* Chunlin Duan, for the contribution of agents' theory development of fashion information flow
* Qi Wang, for the contribution of making the search faster at low-level
* Andrej Karpathy, for the contribution of developing the term vibe coding

### Tier 2
* Phyllis Frankl, https://scholar.google.com/citations?hl=en&user=XE683E8AAAAJ, for the contribution of the agent's robotness
* Keith Ross, https://sites.google.com/nyu.edu/keithross, for the contribution of agent's communication network design
* Edward Wong, https://engineering.nyu.edu/faculty/edward-wong, for the contribution of agent's hallucination in fashion
* Juliana Freire, https://vgc.engineering.nyu.edu/~juliana/, for the contribution of agents' data (mostly state and actions) storage & indexing & querying infra
* Claudio Silva, https://engineering.nyu.edu/faculty/claudio-silva, for the contribution of agents' data (mostly state and actions) viz & analysis & prediction infra
* Nasir Memon, https://engineering.nyu.edu/faculty/nasir-memon, for the contribution of agents' on & off networking infra
* Lisa Hellerstein, https://wp.nyu.edu/tandonschoolofengineering-lisahellerstein/, for the contribution of agents' vertical database & knowledge base in fashion
* Yann LeCun, https://yann.lecun.com/, for the contribution of 
* Jeff Dean, https://x.com/jeffdean, for the contribution of evaluation on service latency, system throughput and coding
* Linus Torvalds, https://linustorvaldslinux.weebly.com/, for the contribution of os kernel capabilities
* Michael A. Arbib, https://viterbi.usc.edu/directory/faculty/Arbib/Michael, for the contribution of mapping capabilities to brain regions
* Ellis Horowitz, https://ellishorowitz.com/, for the contribution of application level internet arch
* Laurent Itti, http://ilab.usc.edu/itti/, for the contribution of agent planning
* David Kempe, https://www.david-kempe.com/, for the contribution of algorithms complexity analysis in time and space

## references part 2 - hardware and software tools
* ROS, https://www.ros.org/, for the contribution of low level arch
* Genesis, https://genesis-embodied-ai.github.io/
* PyTorch, https://pytorch.org/, for the contribution of deep learning framework

## references part 3 - typical books
* AUTONOMOUS LEARNING FROM THE ENVIRONMENT by Weimin Shen, 1994
* Building a General Theory of Evolution by Leonard Adleman, 2024
* Artificial Intelligence: A Modern Approach by Stuart Russell and Peter Norvig, 2022
* ? Who Needs Emotions? The Brain Meets the Robot by Michael A. Arbib, 2005
* ? When brains meet buildings by Michael A. Arbib, 2024

## references part 4 - papers
4. Cite the Google 2017 paper, attention is all you need
6. Cite the chatbot from Doubao
7. Cite the improved chatbot from DeepSeek
8. Cite the agent ai paper from Feifei Li et al.
10. Cite the course from Erdem Bıyık of USC
12. the Agent AI: Surveying the Horizons of Multimodal Interaction paper
13. A small Collatz Rule without the Plus One paper by Kevin Knight
14. A survey on 3D scene reconstruction by Yuanlie He
15. A survey on intelligent embedded system by Yongquan Yu
16. self2self by Yuhui Quan
18. Generation Models with KB by Wei, Chunlin and Yunchi

## references part 5 - courses
* Kaiming He, Deep Generative Models, https://mit-6s978.github.io/

## references part 6 - misc & belief
* GDUT, https://english.gdut.edu.cn/, for the contribution of 
* USC trojans, https://www.usc.edu/we-are-trojans/, for the contribution of the motto to be a symbol of victory, triumph, and regeneration
* NYU traditions, https://www.nyu.edu/faculty/governance-policies-and-procedures/faculty-handbook/the-university/history-and-traditions-of-new-york-university/university-traditions.html, for the contribution of the motto to be Perstare et Praestare
* SCUT, https://www.scut.edu.cn/en/, for the contribution of

## references part 7 - 如何构建智慧图
1. 智慧图概念：智慧图是算法妈妈的知识产权产物，存在于智能体减脂相关论文中，未详细探讨其训练与预测。它以“元想法”替代深度神经网络中的神经元，元想法依功能分为感知、计划、推理、行动等类型，相比神经元更复杂高效，承载更多智慧。
2. 元想法特性：元想法具有生命周期，不同元想法的生命周期相互连接形成元想法桥，存在非强因果关系。外界信号变化促使感知空间中元想法增多、减少、消亡或更新连接边权重。
3. 智能体面临挑战与应对：智能体面临感知局限挑战，如未接触相关事物就难形成对应元想法。可通过拓展数据获取渠道、利用迁移学习解决。为扩大感知空间，算法妈妈寻找具身智能厂商合作。
4. 智能体空间拓展：智能体从感知空间获取数据，如小红书笔记，生成元想法并传递到计划空间，产生更多计划元想法，实现智能体进化与计划空间拓展。
5. 推理机制探讨：复杂任务需推理，简单任务无需。现有推理技术存在推理时间过长等问题，可考虑混合推理机制，简单问题直接检索知识库，复杂问题启用复杂推理方法。
6. 循环训练与奖励函数：智慧图采用循环式训练流程，元想法在感知、计划、推理、行动空间循环，过程中元想法发生增减并建立因果联系。通过奖励函数量化智能体对环境影响，奖励函数依环境类型设计，可存在看似不合理奖励，强调灵活性，通过超参数调整和环境学习优化。
